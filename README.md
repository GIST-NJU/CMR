# Composite Metamorphic Relations (CMRs) for DNN Testing

This repository is supplementary to the following paper **"How Composite Metamorphic Relations Enhance Test Effectiveness of DNN Testing: An Empirical Study"**.

### ğŸ’» Project Structure

```
CMR
â”œâ”€â”€ source                # Source test images
â”œâ”€â”€ followup              # Follow-up test images
â”œâ”€â”€ models                # DNNs under test
â”œâ”€â”€ figures               # Figures for RQs
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ results
â”‚Â Â  â”œâ”€â”€ errors            # Failure rate and fault type metrics
â”‚Â Â  â”œâ”€â”€ features          # Feature representations of test images
â”‚Â Â  â”œâ”€â”€ predictions       # Original prediction results
â”‚Â Â  â””â”€â”€ validity          # Automated validator and validation results
â”œâ”€â”€ RQs.ipynb             # Codes for analysing data and generating figures and tables
â””â”€â”€ src                   # Codes for reproducing experiment
```

### âš™ï¸ Requirements 

Run the following command to install the dependencies required:

```bash
conda create -n cmr python=3.8.18
conda activate cmr
pip install -r requirements.txt
```

### ğŸ“¦ Subject Datasets and DNNs

The experiment is performed on five DNNs, trained on five popular image recognition related datasets:

* **AlexNet @ MNIST** (single-label classification)
* **DenseNet @ Caltech256** (single-label classification)
* **MSRN @ VOC** (multi-label classification)
* **MLD @ COCO** (multi-label classification)
* **Faceptor @ UTKFace** (regression-based facial image estimation)

The DNNs trained can be download from [here](https://www.dropbox.com/scl/fo/x9et5salo528e8inh2999/ANrIfVqVdQqvUrVFzkKiiu8?rlkey=hetb4y6f7hwtqzeay9nwz1fpn&dl=0). You need to put these models in the `models/` directory.

The test sets of these datasets (all of which are used as source test images) can be downloaded [here](https://www.dropbox.com/scl/fo/zfqodjegi4wh0n04mlh7d/AHd8P5BftYNTmszXqygRudE?rlkey=wowwl40k8hr2mmy3shyo420zn&dl=0). You need to put these images in the `source/` directory.


### ğŸ›ï¸ Component MRs

The experiment involves a set of seven representative component MRs. The implementation of these MRs is in the `src/mr_utils.py` file.

| MR   | Image Transformation | Identifier Used |
| ---- | -------------------- | --------------- |
| MR1  | Brightness           | 1               |
| MR2  | Contrast             | 3               |
| MR3  | Sharpness            | 2               |
| MR4  | Blur (Gaussian)      | 4               |
| MR5  | Rotation             | 0               |
| MR6  | Shear (Horizontal)   | 5               |
| MR7  | Translation          | 6               |


### ğŸ“ƒ Experimental Data

The `figures` directory contains all figures presented in the paper:

* *RQ1*: Proportion of valid follow-up test images generated by CMRs
* *RQ2*: The overlap of fault types that are uncovered by CMR, the strongest MR, and all component MRs
* *RQ3.1*: Difference in Failure Rate (DFR) and Fault Type (DFT) between CMR and its strongest and average-performing component MR
* *RQ3.2*: Relationship between DFR (DFT) and âˆ†M values observed

The `results` directory contains the raw experimental results. Note that the original files included in this directory are typically large, so you need to download them separately and put them into their respective sub-directories.

##### 1. Original Prediction Outputs

The `predictions` directory ([download](https://www.dropbox.com/scl/fo/moicow2jgo0q05pgmi6gq/ACkrFH2xQKBdzJ-VqlvSSQE?rlkey=mw75vfwv9gz7pux9cleutryuv&dl=0)) contains the original prediction outputs of the model on source and follow-up images.


##### 2. Validity of Test Inputs

The `validity` directory ([download](https://www.dropbox.com/scl/fo/0cicv66v6a5eex6rjbkpn/AGgBgdneMProMpCZIG5Riq4?rlkey=qpbthrzlz56sc3bgthz3609nk&dl=0)) contains the files for running the *SelfOracle* method, and the results obtained, including:

* `[Dataset]_VAE.pth`: the VAE trained for each dataset
* `[Dataset]_threshold.txt`: the threshold that is automatically derived based on the VAE and rate of false alarm (0.01%)
* `[Dataset]_validity.npy`: the validity of follow-up test images that *SelfOracle* determines 

This directory also contains the follow-up test images sampled for manual analysis, as displayed in the `sampled` directory. The `human_validation.csv`  file gives the manual validation results: Each line corresponds to a follow-up test image that is manually determined as semantically *invalid*, where the three columns indicate the dataset name, the validity determined by *SelfOracle* (1 indicates invalid), and the index of the follow-up test image.


##### 3. Failure and Fault Revelation

The `error` directory ([download](https://www.dropbox.com/scl/fo/djz19v7z6zevl7rl0gewr/ALmhuzP_NqHgkvYJsxZ1E1A?rlkey=0h1zhzqovcerion5egpmlmtew&dl=0)) contains the Failure Rate (FR) and Fault Type (FT) values calculated for each individual MR and CMR, as saved in `failure_[DNN].pkl` and `fault_[DNN].pkl` files, respectively.


##### 4. Complementary MRs

The `features` directory ([download](https://www.dropbox.com/scl/fo/5faddj9zfczyaw4lr33rg/AMO1Wg_lhfuUaAmr2Nt5Xa0?rlkey=2wuru62a9tf5yhjsq0slavsy8&dl=0)) contains the extracted features of source and follow-up test images for analysing complmentary MRs.


### ğŸ› ï¸ Reproducing Experiment

The following scripts can be used to reproduce the complete experiment and evaluation process. To generate tables and figures presented in the paper, run the commands in `RQs.ipynb`.

##### 1. Generate follow-up test images

```bash
python generate_followup.py --dataset COCO --strength 2
```
The `--dataset` parameter specifies the dataset name, and `--strength` specifies the composition strength applied. The follow-up test images generated by employing the input mappings of the specified CMRs will be saved in `followup/dataset/cmr` directory (e.g., `followup/COCO/31`).

##### 2. Validate follow-up test images

```bash
python selforacle.py --dataset COCO
```
This will run the *SelfOracle* method to determine the validity of test images in `followup/dataset/cmr` directory, and produce results as included in  `results/SelfORacle/` directory.

##### 3. Execute DNNs Under Test

```bash
python predict.py --dataset COCO            # execute source test images
python predict.py --dataset COCO --followup # execute follow-up test images
```
This will run the DNN to make predications of the test images, and produce results as included in  `results/predictions/` directory.

##### 4. Evaluate Failure and Fault Revelation Capability

```bash
python count_failure_fault.py --dataset COCO
```
This will base on the prediction outputs to calculate the failure and fault revelation related metrics, and produce the results as included in `results/errors/` directory.

##### 5. Calculate the âˆ†M Measure 

```bash
python extract_features.py
```

This will calculate the feature representation of each test image, and produce the results as included in `results/features/` directory.
