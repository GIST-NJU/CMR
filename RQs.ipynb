{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "# import cv2 as cv\n",
    "# from PIL import Image, ImageEnhance\n",
    "# import matplotlib .pyplot as plt\n",
    "from itertools import permutations, combinations\n",
    "# import scipy.stats as stats\n",
    "import pandas as pd\n",
    "# from pylatex import Document, Section, Subsection, Tabular, MultiColumn, MultiRow\n",
    "import torch\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import matplotlib.cm as cm\n",
    "from src.mr_utils import mrs\n",
    "\n",
    "mr_num = len(mrs)\n",
    "strength_max = 5\n",
    "datasets = ['MNIST', 'Caltech256', 'VOC', 'COCO']\n",
    "test_cases_num = {'MNIST': 10000, 'Caltech256': 3061, 'VOC':4952, 'COCO':40775}\n",
    "models = {'MNIST': ['AlexNet'],\n",
    "\t\t'Caltech256': ['DenseNet121'],\n",
    "\t\t'VOC': ['MSRN'],\n",
    "\t\t'COCO': ['MLD']}\n",
    "model_names = ['MNIST_AlexNet_9938', 'Caltech256_DenseNet121_6838', 'VOC_MSRN', 'COCO_MLD']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ1 Validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, dataset in enumerate(datasets):\n",
    "\tresult_selfOracle = np.load(f'results/SelfOracle/{dataset}_validity.npy', allow_pickle=True).item()\n",
    "\twith open(f'results/SelfOracle/{dataset}_threshold.txt', 'r') as file:\n",
    "\t\tfor line in file:\n",
    "\t\t\tif line.split(':')[0] == 'Threshold':\n",
    "\t\t\t\tth = float(line.split(':')[1])\n",
    "\n",
    "\tdata = [[] for _ in range(strength_max)]\n",
    "\tfor cmr in result_selfOracle.keys():\n",
    "\t\tif len(cmr) > strength_max:\n",
    "\t\t\tcontinue\n",
    "\t\tdata[len(cmr)-1].append(len(np.where(np.array(result_selfOracle[cmr]) <= th)[0]) / \n",
    "\t\t\t\t\t\t\t\t\tlen(result_selfOracle[(0,)]) * 100)\n",
    "\n",
    "\tplt.figure(figsize=(3, 3))\n",
    "\tplt.boxplot(data, patch_artist=False)\n",
    "\n",
    "\tplt.xlabel(f'Composition strength ($k$)')\n",
    "\tplt.ylabel('Proportion of valid images')\n",
    "\n",
    "\tif i > 0:\n",
    "\t\tplt.ylim(96, 100.1)\n",
    "\t\tplt.yticks([96, 97, 98, 99, 100])  # 设定刻度\n",
    "\n",
    "\tplt.tight_layout()\n",
    "\tplt.savefig(f'figures/RQ1/{dataset}_validity.pdf', dpi=600)\n",
    "\t#plt.show()\n",
    "\tplt.close()\n",
    "\t# medians = [np.median(group) if group else np.nan for group in data]\n",
    "\t# for k, m in enumerate(medians, start=1):\n",
    "\t# \tprint(data[k-1])\n",
    "\t# \tprint(f\"{dataset}: k={k}, median={m:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(dataset, model):\n",
    "\tfor i in range(len(model_names)):\n",
    "\t\tif dataset+'_'+model in model_names[i]:\n",
    "\t\t\treturn model_names[i]\n",
    "\n",
    "def get_validity(dataset):\n",
    "\tfilename_validity = 'results/SelfOracle/' + dataset + '_validity.npy'\n",
    "\tfilename_threshold = 'results/SelfOracle/' + dataset + '_threshold.txt'\n",
    "\tvalidity = np.load(filename_validity, allow_pickle=True).item()\n",
    "\twith open(filename_threshold) as f:\n",
    "\t\tlines = f.readlines()\n",
    "\t\tthreshold = float(lines[1].split(':')[1].strip())\n",
    "\t# print(threshold)\n",
    "\tfor mr in validity:\n",
    "\t\tfor i in range(len(validity[mr])):\n",
    "\t\t\tif validity[mr][i] <= threshold:\n",
    "\t\t\t\tvalidity[mr][i] = True\n",
    "\t\t\telse:\n",
    "\t\t\t\tvalidity[mr][i] = False\n",
    "\treturn validity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Store errors\n",
    "\n",
    "# def error_revealing(dataset, mr, pred_source, pred_followup, validity_followup):\n",
    "# \tif dataset in  ['MNIST', 'Caltech256']:\n",
    "# \t\terror = []\n",
    "# \t\tfor i in range(len(pred_source)):\n",
    "# \t\t\tif validity_followup[mr][i] and (pred_followup[mr][i] != pred_source[i]):\n",
    "# \t\t\t\terror.append(i)\n",
    "# \telse:\n",
    "# \t\tpred_f = pred_followup[mr]\n",
    "# \t\tpred_f = pred_f.drop(columns=['img'])\n",
    "# \t\tpred_f = pred_f.to_numpy()\n",
    "# \t\tpred_f = {i: set(row[~pd.isna(row)]) for i, row in enumerate(pred_f)}\n",
    "# \t\terror = []\n",
    "# \t\tfor i in range(len(pred_source)):\n",
    "# \t\t\tif validity_followup[mr][i] and (pred_f[i] != pred_source[i]):\n",
    "# \t\t\t\terror.append(i)\n",
    "# \treturn error\n",
    "\n",
    "# for model_name in model_names:\n",
    "# \tdataset = model_name.split('_')[0]\n",
    "# \tstrength = len(mrs)\n",
    "# \terror = {}\n",
    "\n",
    "# \tif dataset in ['MNIST', 'Caltech256']:\n",
    "# \t\tpred_source = np.load(os.path.join('results', 'predictions', dataset, model_name+'_source.npy'))\n",
    "# \telse:\n",
    "# \t\tpred_source = pd.read_csv(os.path.join('results', 'predictions', dataset, model_name+'_source.csv'), low_memory=False)\n",
    "# \t\tpred_source = pred_source.drop(columns=['img'])\n",
    "# \t\tpred_source = pred_source.to_numpy()\n",
    "# \t\tpred_source = {i: set(row[~pd.isna(row)]) for i, row in enumerate(pred_source)}\n",
    "\n",
    "# \tpred_followup = np.load(os.path.join('results', 'predictions', dataset, model_name+'_followup.npy'),allow_pickle=True).item()\n",
    "# \t#print(len(pred_followup))\n",
    "# \tvalidity_followup = get_validity(dataset)\n",
    "# \tfor mr in pred_followup:\n",
    "# \t\terror[mr] = error_revealing(dataset, mr, pred_source, pred_followup, validity_followup)\n",
    "\t\n",
    "# \twith open(f'results/errors/error_{model_name}.pkl', 'wb') as f:\n",
    "# \t\tpickle.dump(error, f)\n",
    "# \tprint(model_name, 'Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save fault\n",
    "\n",
    "# errors = {}\n",
    "# for model_name in model_names:\n",
    "# \twith open(f'results/errors/error_{model_name}.pkl', 'rb') as f:\n",
    "# \t\terror = pickle.load(f)\n",
    "# \t\terrors[model_name] = error\n",
    "\n",
    "# for dataset in datasets:\n",
    "# \tfor index, model in enumerate(models[dataset]):\n",
    "# \t\tmodel_name = get_model_name(dataset, model)\n",
    "\n",
    "# \t\tpred_followup = np.load(os.path.join('results', 'predictions', dataset, model_name+'_followup.npy'),allow_pickle=True).item()\n",
    "# \t\tif dataset in ['MNIST', 'Caltech256']:\n",
    "# \t\t\tpred_source = np.load(os.path.join('results', 'predictions', dataset, model_name+'_source.npy'))\n",
    "# \t\telse:\n",
    "# \t\t\tpred_source = pd.read_csv(os.path.join('results', 'predictions', dataset, model_name+'_source.csv'), low_memory=False)\n",
    "# \t\t\tpred_source = pred_source.drop(columns=['img'])\n",
    "# \t\t\tpred_source = pred_source.to_numpy()\n",
    "# \t\t\tpred_source = {i: tuple(sorted(set(row[~pd.isna(row)]))) for i, row in enumerate(pred_source)}\n",
    "\t\t\n",
    "# \t\t\tfor key in pred_followup:\n",
    "# \t\t\t\tt = pred_followup[key]\n",
    "# \t\t\t\tt = t.drop(columns=['img'])\n",
    "# \t\t\t\tt = t.to_numpy()\n",
    "# \t\t\t\tt = {i: tuple(sorted(set(row[~pd.isna(row)]))) for i, row in enumerate(t)}\n",
    "# \t\t\t\tpred_followup[key] = t\n",
    "# \t\tfaults_cmr = {}\n",
    "# \t\tfaults_all = set()\n",
    "# \t\tfor i in range(strength_max):\n",
    "# \t\t\tfor cmr in permutations(range(len(mrs)), i + 1):\n",
    "# \t\t\t\tfailure = errors[model_name][cmr]\n",
    "# \t\t\t\tfaults = {}\n",
    "# \t\t\t\tfor f in failure:\n",
    "# \t\t\t\t\tsource_label = pred_source[f]\n",
    "# \t\t\t\t\tfollowup_label = pred_followup[cmr][f]\n",
    "# \t\t\t\t\tfaults[f] = (source_label, followup_label)\n",
    "# \t\t\t\tfaults_cmr[cmr] = faults\n",
    "# \t\t\t\tfaults_all.update(faults.values())\n",
    "# \t\twith open(f'results/errors/fault_{model_name}.pkl', 'wb') as f:\n",
    "# \t\t\tpickle.dump(faults_cmr, f)\n",
    "# \t\tprint(dataset, model, len(faults_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = {}\n",
    "for model_name in model_names:\n",
    "    with open(f'results/errors/error_{model_name}.pkl', 'rb') as f:\n",
    "        error = pickle.load(f)\n",
    "        errors[model_name] = error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST AlexNet\n",
      " & 0.98\\% & 1.40\\% & 0.0 & 0.0 \\\\\n",
      "26.7 33.8 46.4\n",
      "4 3 19 15 9\n",
      "-------------------------------------------------------------------------------\n",
      "Caltech256 DenseNet121\n",
      " & 10.27\\% & 17.17\\% & 0.0 & 0.0 \\\\\n",
      "706.3 479.2 981.6\n",
      "293 138 274 205 364\n",
      "-------------------------------------------------------------------------------\n",
      "VOC MSRN\n",
      " & 5.61\\% & 10.38\\% & 0.0 & 0.0 \\\\\n",
      "399.9 321.5 512.1\n",
      "101 66 232 89 124\n",
      "-------------------------------------------------------------------------------\n",
      "COCO MLD\n",
      " & 7.20\\% & 24.07\\% & 0.0 & 0.0 \\\\\n",
      "18298.3 15941.0 34156.3\n",
      "9827 2253 6219 9722 15963\n",
      "-------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Compare the total failure ratio and the total number of faults\n",
    "\n",
    "for dataset in datasets:\n",
    "\tfor model in models[dataset]:\n",
    "\t\tprint(dataset, model)\n",
    "\t\tmodel_name = get_model_name(dataset, model)\n",
    "\t\tvalidity_followup = get_validity(dataset)\n",
    "\t\tsource_num = len(validity_followup[(0,)])\n",
    "\t\twith open(f'results/errors/fault_{model_name}.pkl', 'rb') as f:\n",
    "\t\t\tfault_all = pickle.load(f)\n",
    "\t\tcmr_num = 0\n",
    "\t\tfailure_CMR_MAX, failure_CMR_MEAN = 0, 0\n",
    "\t\tfault_CMR_MAX, fault_CMR_MEAN = 0, 0\n",
    "\n",
    "\t\tfault_cmr, fault_max, fault_union = 0, 0, 0\n",
    "\t\tfault1, fault2, fault3, fault4, fault5 = 0, 0, 0, 0, 0\n",
    "\n",
    "\t\tfor i in range(2, strength_max+1):\n",
    "\t\t\tfor cmr in permutations(range(len(mrs)), i):\n",
    "\t\t\t\tcmr_num += 1\n",
    "\t\t\t\tfailure_com, fault_com = [], []\n",
    "\t\t\t\tfailure_com_union = set()\n",
    "\t\t\t\tfault_com_union = set()\n",
    "\t\t\t\tfault_com_max = set()\n",
    "\t\t\t\tfor com in cmr:\n",
    "\t\t\t\t\tfailure_com_union.update(errors[model_name][(com,)])\n",
    "\t\t\t\t\tfailure_com.append(len(errors[model_name][(com,)]) / source_num * 100)\n",
    "\t\t\t\t\tfault_com.append(len(set(fault_all[(com,)].values())))\n",
    "\t\t\t\t\tfault_com_union.update(set(fault_all[(com,)].values()))\n",
    "\t\t\t\t\tif len(set(fault_all[(com,)].values())) > len(fault_com_max):\n",
    "\t\t\t\t\t\tfault_com_max = set(fault_all[(com,)].values())\n",
    "\n",
    "\t\t\t\tfailure_CMR_MAX += len(errors[model_name][cmr]) / source_num * 100 - max(failure_com)\n",
    "\t\t\t\tfailure_CMR_MEAN += len(errors[model_name][cmr]) / source_num * 100 - sum(failure_com)/i\n",
    "\n",
    "\t\t\t\tfault_cmr += len(set(fault_all[cmr].values()))\n",
    "\t\t\t\tfault_max += max(fault_com)\n",
    "\t\t\t\tfault_union += len(fault_com_union)\n",
    "\n",
    "\t\t\t\tfault1 += len(set(fault_all[cmr].values()) - fault_com_union)\n",
    "\t\t\t\tfault2 += len((set(fault_all[cmr].values()) & fault_com_union) - fault_com_max)\n",
    "\t\t\t\tfault3 += len(set(fault_all[cmr].values()) & fault_com_max)\n",
    "\t\t\t\tfault4 += len(fault_com_max - set(fault_all[cmr].values()))\n",
    "\t\t\t\tfault5 += len(fault_com_union - (set(fault_all[cmr].values()) | fault_com_max))\n",
    "\n",
    "\t\tdfr_max = failure_CMR_MAX / cmr_num\n",
    "\t\tdfr_mean = failure_CMR_MEAN / cmr_num\n",
    "\t\tdft_max = fault_CMR_MAX / cmr_num\n",
    "\t\tdft_mean = fault_CMR_MEAN / cmr_num\n",
    "\t\tfault_cmr, fault_max, fault_union = fault_cmr/cmr_num, fault_max/cmr_num, fault_union/cmr_num\n",
    "\t\tfault1, fault2, fault3, fault4, fault5 = fault1/cmr_num, fault2/cmr_num, fault3/cmr_num, fault4/cmr_num, fault5/cmr_num\n",
    "\t\tprint(f\" & {dfr_max:.2f}\\% & {dfr_mean:.2f}\\% & {dft_max:.1f} & {dft_mean:.1f} \\\\\\\\\")\n",
    "\t\tprint(f\"{fault_cmr:.1f} {fault_max:.1f} {fault_union:.1f}\")\n",
    "\t\tprint(f\"{fault1:.0f} {fault2:.0f} {fault3:.0f} {fault4:.0f} {fault5:.0f}\")\n",
    "\n",
    "\tprint('-------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw box plot of Failure\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def compare_with_com_failure_4boxplot(dataset, model):\n",
    "\tmodel_name = get_model_name(dataset, model)\n",
    "\tvalidity_followup = get_validity(dataset)\n",
    "\tresult_delta_max, result_delta_mean = [], []\n",
    "\tsource_num = len(validity_followup[(0,)])\n",
    "\tfor i in range(1, strength_max): \n",
    "\t\tdelta_max, delta_mean = [], []\n",
    "\t\tcmr_num = 0\n",
    "\t\tfor cmr in permutations(range(len(mrs)), i + 1):\n",
    "\t\t\tcmr_num += 1\n",
    "\t\t\tcmr_failure_ratio = len(errors[model_name][cmr]) / source_num\n",
    "\t\t\tcom_failure_ratio = []\n",
    "\t\t\tfor mr in cmr:\n",
    "\t\t\t\tmr = (mr,)\n",
    "\t\t\t\tcom_failure_ratio.append(len(errors[model_name][mr]) / source_num)\n",
    "\t\t\tdelta_max.append(cmr_failure_ratio - max(com_failure_ratio))\n",
    "\t\t\tdelta_mean.append(cmr_failure_ratio - sum(com_failure_ratio) / len(com_failure_ratio))\n",
    "\t\tresult_delta_max.append(delta_max)\n",
    "\t\tresult_delta_mean.append(delta_mean)\n",
    "\treturn result_delta_max, result_delta_mean\n",
    "\n",
    "def draw_boxplot_failure(dataset, model):\n",
    "\tdelta_max, delta_mean = compare_with_com_failure_4boxplot(dataset, model)\n",
    "\tx_labels = [2, 3, 4, 5]\n",
    "\tgroup_labels = [r\"$\\mathit{DFR}_{\\mathit{best}}$\", r\"$\\mathit{DFR}_{\\mathit{mean}}$\"]\n",
    "\n",
    "\trecords = []\n",
    "\tfor i, x in enumerate(x_labels):\n",
    "\t\tfor group, data in zip(group_labels, [delta_max[i], delta_mean[i]]):\n",
    "\t\t\tfor value in data:\n",
    "\t\t\t\trecords.append({'X': x, 'Group': group, 'Value': value})\n",
    "\tdf = pd.DataFrame(records)\n",
    "\t# 绘图\n",
    "\tplt.figure(figsize=(4, 4))\n",
    "\tsns.boxplot(x='X', y='Value', hue='Group', data=df, palette='Set2', width=0.6, flierprops=dict(marker='o', markersize=3, linestyle='none') )\n",
    "\t#plt.title('Failure ' + dataset)\n",
    "\tplt.xlabel(f'$k$')\n",
    "\tplt.ylabel('Difference in failure ratio')\n",
    "\tplt.legend()\n",
    "\tplt.tight_layout()\n",
    "\tplt.savefig(f\"figures/RQ3.1/failure_{dataset}_{model}_box_plot.pdf\", dpi=300, bbox_inches='tight')\n",
    "\t#plt.show()\n",
    "\tplt.close()\n",
    "\n",
    "\t# print(f\"\\n===== Failure Ratio Difference: {dataset}, {model} =====\")\n",
    "\t# for i, k in enumerate(x_labels):\n",
    "\t# \tfor group_name, values in zip(group_labels, [delta_max[i], delta_mean[i]]):\n",
    "\t# \t\tif not values:\n",
    "\t# \t\t\tcontinue\n",
    "\t# \t\tseries = pd.Series(values)\n",
    "\t# \t\tmedian = series.median()\n",
    "\t# \t\tq1 = series.quantile(0.25)\n",
    "\t# \t\tq3 = series.quantile(0.75)\n",
    "\t# \t\tmin_val = series.min()\n",
    "\t# \t\tmax_val = series.max()\n",
    "\t# \t\tneg_ratio = (series < 0).mean()\n",
    "\t# \t\tprint(f\"k = {k}, Group = {group_name}\")\n",
    "\t# \t\tprint(f\"  Median = {median:.4f}, Q1 = {q1:.4f}, Q3 = {q3:.4f}\")\n",
    "\t# \t\tprint(f\"  Min = {min_val:.4f}, Max = {max_val:.4f}, Negative ratio = {neg_ratio:.2%}\")\n",
    "\n",
    "for dataset in datasets:\n",
    "\tfor model in models[dataset]:\n",
    "\t\tdraw_boxplot_failure(dataset, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw box plot of Fault\n",
    "\n",
    "def compare_with_com_fault_4boxplot(dataset, model):\n",
    "\tmodel_name = get_model_name(dataset, model)\n",
    "\twith open(f'results/errors/fault_{model_name}.pkl', 'rb') as f:\n",
    "\t\tfault_all = pickle.load(f)\n",
    "\t# for i in range(len(mrs)):\n",
    "\t# \tprint(len(set(fault_all[(i,)])), end=' ')\n",
    "\t# print()\n",
    "\tresult_delta_union, result_delta_max, result_delta_mean = [], [], []\n",
    "\tresult_cmr_union_insert, result_cmr_union_diff = [], []\n",
    "\tfor i in range(1, strength_max):\n",
    "\t\tdelta_union, delta_max, delta_mean = [], [], []\n",
    "\t\tfault_cmr_union_insert, fault_cmr_minus_union, fault_union_minus_cmr = [], [], []\n",
    "\t\tfor cmr in permutations(range(len(mrs)), i + 1):\n",
    "\t\t\tf_cmr = set(fault_all[cmr].values())\n",
    "\t\t\tcom_fault = []\n",
    "\t\t\tcom_fault_union = set()\n",
    "\t\t\tfor mr in cmr:\n",
    "\t\t\t\tmr = (mr,)\n",
    "\t\t\t\tcom_fault.append(len(set(fault_all[mr].values())))\n",
    "\t\t\t\tcom_fault_union.update(fault_all[mr].values())\n",
    "\n",
    "\t\t\tdelta_union.append(len(f_cmr) - len(com_fault_union))\n",
    "\t\t\tdelta_max.append(len(f_cmr) - max(com_fault))\n",
    "\t\t\tdelta_mean.append(len(f_cmr) - sum(com_fault) / len(com_fault))\n",
    "\n",
    "\t\t\tfault_cmr_union_insert.append(len(f_cmr & com_fault_union))\n",
    "\t\t\tfault_cmr_minus_union.append(len(f_cmr - com_fault_union))\n",
    "\t\tresult_delta_union.append(delta_union)\n",
    "\t\tresult_delta_max.append(delta_max)\n",
    "\t\tresult_delta_mean.append(delta_mean)\n",
    "\t\tresult_cmr_union_insert.append(fault_cmr_union_insert)\n",
    "\t\tresult_cmr_union_diff.append(fault_cmr_minus_union)\n",
    "\t#return result_delta_union, result_delta_max, result_delta_mean, result_cmr_union_insert, result_cmr_union_diff\n",
    "\treturn result_delta_max, result_delta_mean\n",
    "\n",
    "def draw_boxplot_fault(dataset, model):\n",
    "\tdelta_max, delta_mean = compare_with_com_fault_4boxplot(dataset, model)\n",
    "\n",
    "\tx_labels = [2, 3, 4, 5]\n",
    "\tgroup_labels = [r\"$\\mathit{DFT}_{\\mathit{best}}$\", r\"$\\mathit{DFT}_{\\mathit{mean}}$\"]\n",
    "\n",
    "\trecords = []\n",
    "\tfor i, x in enumerate(x_labels):\n",
    "\t\tfor group, data in zip(group_labels, [delta_max[i], delta_mean[i]]):\n",
    "\t\t\tfor value in data:\n",
    "\t\t\t\trecords.append({'X': x, 'Group': group, 'Value': value})\n",
    "\n",
    "\tdf = pd.DataFrame(records)\n",
    "\n",
    "\tplt.figure(figsize=(4, 4))\n",
    "\tsns.boxplot(x='X', y='Value', hue='Group', data=df, palette='Set2', width=0.6, flierprops=dict(marker='o', markersize=3, linestyle='none') )\n",
    "\t#plt.title('Failure ' + dataset)\n",
    "\n",
    "\tplt.xlabel(f'$k$')\n",
    "\tplt.ylabel('Difference in size of fault types')\n",
    "\tplt.legend()\n",
    "\tplt.tight_layout()\n",
    "\tplt.savefig(f\"figures/RQ3.1/fault_{dataset}_{model}_box_plot.pdf\", dpi=300, bbox_inches='tight')\n",
    "\t# plt.show()\n",
    "\tplt.close()\n",
    "\n",
    "\t# print(f\"\\n===== Fault Number Difference: {dataset}, {model} =====\")\n",
    "\t# for i, k in enumerate(x_labels):\n",
    "\t# \tfor group_name, values in zip(group_labels, [delta_max[i], delta_mean[i]]):\n",
    "\t# \t\tif not values:\n",
    "\t# \t\t\tcontinue\n",
    "\t# \t\tseries = pd.Series(values)\n",
    "\t# \t\tmedian = series.median()\n",
    "\t# \t\tq1 = series.quantile(0.25)\n",
    "\t# \t\tq3 = series.quantile(0.75)\n",
    "\t# \t\tmin_val = series.min()\n",
    "\t# \t\tmax_val = series.max()\n",
    "\t# \t\tneg_ratio = (series < 0).mean()\n",
    "\t# \t\tprint(f\"k = {k}, Group = {group_name}\")\n",
    "\t# \t\tprint(f\"  Median = {median:.4f}, Q1 = {q1:.4f}, Q3 = {q3:.4f}\")\n",
    "\t# \t\tprint(f\"  Min = {min_val:.4f}, Max = {max_val:.4f}, Negative ratio = {neg_ratio:.2%}\")\n",
    "\n",
    "for dataset in datasets:\n",
    "\tfor model in models[dataset]:\n",
    "\t\tdraw_boxplot_fault(dataset, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ3.2 Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check delta Effectiveness w.r.t. Failure\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "for dataset in datasets:\n",
    "\tfilename = f'results/SelfOracle/{dataset}_validity.npy'\n",
    "\tvalidity_followup = get_validity(dataset) \n",
    "\tif dataset == 'MNIST':\n",
    "\t\textractor = 'lenet5'\n",
    "\telse:\n",
    "\t\textractor = 'vgg16'\n",
    "\tsave_path = os.path.join('results', 'features', extractor, f'{dataset}.pt')\n",
    "\tsource__features = torch.load(save_path)\n",
    "\tfollowup__features_followup = []\n",
    "\tfor i in range(len(mrs)):\n",
    "\t\tsave_path = os.path.join('results', 'features', extractor, f'{dataset}_{i}.pt')\n",
    "\t\tfollowup__features_followup.append(torch.load(save_path))\n",
    "\tall_features = [source__features] + followup__features_followup\n",
    "\tall_features = [f.cpu().numpy() for f in all_features]\n",
    "\tall_features = np.concatenate(all_features, axis=0)\n",
    "\tpca = PCA(n_components=8)\n",
    "\treduced_features = pca.fit_transform(all_features)\n",
    "\tsource_length = len(source__features)\n",
    "\tsource_features = reduced_features[:source_length]\n",
    "\tfollowup_features = reduced_features[source_length:]\n",
    "\tfollowup_separated = [followup_features[i * source_length:(i + 1) * source_length] for i in range(7)]\n",
    " \n",
    "\tfor model in models[dataset]:\n",
    "\t\tprint(dataset, model)\n",
    "\t\tmodel_name = get_model_name(dataset, model)\n",
    "\t\tfor i in range(2, strength_max+1):\n",
    "\t\t\tdeltadis, deltaeff = [], []\n",
    "\t\t\tfor com in combinations(range(len(mrs)), i):\n",
    "\t\t\t\tselect_com = com[0]\n",
    "\t\t\t\tfor j in range(1, len(com)):\n",
    "\t\t\t\t\tif len(errors[model_name][(com[j],)]) / sum(validity_followup[(com[j],)]) > len(errors[model_name][(select_com,)]) / sum(validity_followup[(select_com,)]):\n",
    "\t\t\t\t\t\tselect_com = com[j]\n",
    "\t\t\t\tdelta_d = []\n",
    "\t\t\t\tdelta_e = []\n",
    "\t\t\t\tfor cmr in permutations(com):\n",
    "\t\t\t\t\td, f, f_c, v_p_num = 0, 0, 0, 0\n",
    "\t\t\t\t\tfor index in range(source_length):\n",
    "\t\t\t\t\t\tif validity_followup[cmr][index] and validity_followup[(select_com,)][index]:\n",
    "\t\t\t\t\t\t\tv_p_num += 1\n",
    "\t\t\t\t\t\t\tdelta_com = []\n",
    "\t\t\t\t\t\t\tfor c in cmr:\n",
    "\t\t\t\t\t\t\t\tdelta_com.append(followup_separated[c][index] - source_features[index])\n",
    "\t\t\t\t\t\t\tcombined = sum(delta_com)\n",
    "\t\t\t\t\t\t\tdelta = followup_separated[select_com][index] - source_features[index]\n",
    "\t\t\t\t\t\t\td += np.linalg.norm(combined) - np.linalg.norm(delta)\n",
    "\n",
    "\t\t\t\t\t\t\tif index in errors[model_name][(select_com,)]:\n",
    "\t\t\t\t\t\t\t\tf_c += 1\n",
    "\t\t\t\t\t\t\tif index in errors[model_name][cmr]:\n",
    "\t\t\t\t\t\t\t\tf += 1\n",
    "\t\t\t\t\tdelta_d.append(d / v_p_num)\n",
    "\t\t\t\t\tdelta_e.append((f - f_c) / v_p_num)\n",
    "\t\t\t\tdeltadis.append(sum(delta_d) / len(delta_d))\n",
    "\t\t\t\tdeltaeff.append(sum(delta_e) / len(delta_e))\n",
    "\t\t\tcorrelation, p_value = spearmanr(deltadis, deltaeff)\n",
    "\t\t\t# print(dataset, model, f'k={i}')\n",
    "\t\t\t# print('delta distance:', deltadis)\n",
    "\t\t\t# print('delta failure ratio:', deltaeff)\n",
    "\t\t\t# print(len(deltadis), correlation, p_value)\n",
    "\t\t\tplt.figure(figsize=(4, 3.5))\n",
    "\t\t\tplt.scatter(deltadis, deltaeff,  color=\"#002EA6\", s=15)\n",
    "\t\t\tplt.xlabel(r\"$\\Delta_M$\")\n",
    "\t\t\tplt.ylabel(r\"$\\mathit{DFR}_{\\mathit{best}}$\")\n",
    "\n",
    "\t\t\tplt.tight_layout()\n",
    "\t\t\tplt.savefig(f\"figures/RQ3.2/failure_{dataset}_{model}_{i}_scatter_plot.pdf\", dpi=300, bbox_inches='tight')\n",
    "\t\t\t#plt.show()\n",
    "\t\t\tplt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check delta Effectiveness w.r.t. Fault\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "for dataset in datasets:\n",
    "\tfilename = f'results/SelfOracle/{dataset}_validity.npy'\n",
    "\tvalidity_followup = get_validity(dataset) \n",
    "\tif dataset == 'MNIST':\n",
    "\t\textractor = 'lenet5'\n",
    "\telse:\n",
    "\t\textractor = 'vgg16'\n",
    "\tsave_path = os.path.join('results', 'features', extractor, f'{dataset}.pt')\n",
    "\tsource__features = torch.load(save_path)\n",
    "\tfollowup__features_followup = []\n",
    "\tfor i in range(len(mrs)):\n",
    "\t\tsave_path = os.path.join('results', 'features', extractor, f'{dataset}_{i}.pt')\n",
    "\t\tfollowup__features_followup.append(torch.load(save_path))\n",
    "\tall_features = [source__features] + followup__features_followup\n",
    "\tall_features = [f.cpu().numpy() for f in all_features]\n",
    "\tall_features = np.concatenate(all_features, axis=0)\n",
    "\tpca = PCA(n_components=8)\n",
    "\treduced_features = pca.fit_transform(all_features)\n",
    "\tsource_length = len(source__features)\n",
    "\tsource_features = reduced_features[:source_length]\n",
    "\tfollowup_features = reduced_features[source_length:]\n",
    "\tfollowup_separated = [followup_features[i * source_length:(i + 1) * source_length] for i in range(7)]\n",
    "\n",
    "\tfor model in models[dataset]:\n",
    "\t\tprint(dataset, model)\n",
    "\t\tmodel_name = get_model_name(dataset, model)\n",
    "\t\twith open(f'results/errors/fault_{model_name}.pkl', 'rb') as f:\n",
    "\t\t\tfault_all = pickle.load(f)\n",
    "\t\tfor i in range(2, strength_max+1):\n",
    "\t\t\tdeltadis, deltaeff = [], []\n",
    "\t\t\tfor com in combinations(range(len(mrs)), i):\n",
    "\t\t\t\tselect_com = com[0]\n",
    "\t\t\t\tfor j in range(1, len(com)):\n",
    "\t\t\t\t\tif (len(set(fault_all[(com[j],)].values())) > len(set(fault_all[(select_com,)].values()))):\n",
    "\t\t\t\t\t\tselect_com = com[j]\n",
    "\n",
    "\t\t\t\tdelta_d = []\n",
    "\t\t\t\tdelta_e = []\n",
    "\t\t\t\tfor cmr in permutations(com):\n",
    "\t\t\t\t\td, f, f_c, v_p_num = 0, set(), set(), 0\n",
    "\t\t\t\t\tfor index in range(source_length):\n",
    "\t\t\t\t\t\tif validity_followup[cmr][index] and validity_followup[(select_com,)][index]:\n",
    "\t\t\t\t\t\t\tv_p_num += 1\n",
    "\n",
    "\t\t\t\t\t\t\tdelta_com = []\n",
    "\t\t\t\t\t\t\tfor c in cmr:\n",
    "\t\t\t\t\t\t\t\tdelta_com.append(followup_separated[c][index] - source_features[index])\n",
    "\t\t\t\t\t\t\tcombined = sum(delta_com)\n",
    "\t\t\t\t\t\t\tdelta = followup_separated[select_com][index] - source_features[index]\n",
    "\t\t\t\t\t\t\td += np.linalg.norm(combined) - np.linalg.norm(delta)\n",
    "\n",
    "\t\t\t\t\t\t\t#print(cmr, d, index)\n",
    "\t\t\t\t\t\t\tif index in errors[model_name][(select_com,)]:\n",
    "\t\t\t\t\t\t\t\tf_c.add(fault_all[(select_com,)][index])\n",
    "\t\t\t\t\t\t\tif index in errors[model_name][cmr]:\n",
    "\t\t\t\t\t\t\t\tf.add(fault_all[cmr][index])\n",
    "\t\t\t\t\tdelta_d.append(d / v_p_num)\n",
    "\t\t\t\t\tdelta_e.append((len(f) - len(f_c)))\n",
    "\t\t\t\t#print(com, select_com, delta_d, delta_e)\n",
    "\t\t\t\tdeltadis.append(sum(delta_d) / len(delta_d))\n",
    "\t\t\t\tdeltaeff.append(sum(delta_e) / len(delta_e))\n",
    "\t\t\tcorrelation, p_value = spearmanr(deltadis, deltaeff)\n",
    "\t\t\t# print(dataset, model, f'k={i}')\n",
    "\t\t\t# print('delta distance:', deltadis)\n",
    "\t\t\t# print('delta fault number:', deltaeff)\n",
    "\t\t\t# print(len(deltadis), correlation, p_value)\n",
    "\t\t\tplt.figure(figsize=(4, 3.5))\n",
    "\t\t\tplt.scatter(deltadis, deltaeff,  color=\"#002EA6\", s=15)\n",
    "\t\t\tplt.xlabel(r\"$\\Delta_M$\")\n",
    "\t\t\tplt.ylabel(r\"$\\mathit{DFT}_{\\mathit{best}}$\")\n",
    "\n",
    "\t\t\tplt.tight_layout()\n",
    "\t\t\tplt.savefig(f\"figures/RQ3.2/fault_{dataset}_{model}_{i}_scatter_plot.pdf\", dpi=300, bbox_inches='tight')\n",
    "\t\t\t#plt.show()\n",
    "\t\t\tplt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ3.3 Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_effect(dataset, model):\n",
    "\tmodel_name = get_model_name(dataset, model)\n",
    "\tprint(model_name)\n",
    "\tvalidity_followup = get_validity(dataset)\n",
    "\twith open(f'results/errors/fault_{model_name}.pkl', 'rb') as f:\n",
    "\t\tfault_all = pickle.load(f)\n",
    "\tsource_num = len(validity_followup[(0,)])\n",
    "\tfor k in range(1, strength_max):\n",
    "\t\tk = k + 1\n",
    "\t\tdfr_max_mean, dfr_max_std, dfr_mean_mean, dfr_mean_std = [], [], [], []\n",
    "\t\tdft_max_mean, dft_max_std, dft_mean_mean, dft_mean_std = [], [], [], []\n",
    "\t\tfor com in combinations(range(len(mrs)), k):\n",
    "\t\t\tdfr_max_com, dfr_mean_com, dft_max_com, dft_mean_com = [], [], [], []\n",
    "\t\t\tfr_max, fr_mean = 0, 0\n",
    "\t\t\tft_max, ft_mean = 0, 0\n",
    "\t\t\tfor mr in com:\n",
    "\t\t\t\tfr_mean += len(errors[model_name][(mr,)]) / source_num\n",
    "\t\t\t\tif len(errors[model_name][(mr,)]) / source_num > fr_max:\n",
    "\t\t\t\t\tfr_max = len(errors[model_name][(mr,)]) / source_num\n",
    "\t\t\t\tft_mean += len(set(fault_all[(mr,)].values()))\n",
    "\t\t\t\tif len(set(fault_all[(mr,)].values())) > ft_max:\n",
    "\t\t\t\t\tft_max = len(set(fault_all[(mr,)].values()))\n",
    "\t\t\tfr_mean, ft_mean = fr_mean / len(com), ft_mean / len(com)\n",
    "\t\t\tfor per in permutations(com):\n",
    "\t\t\t\terror = errors[model_name][per]\n",
    "\t\t\t\tfr = len(error) / source_num\n",
    "\t\t\t\tft = len(set(fault_all[per].values()))\n",
    "\t\t\t\tdfr_max_com.append(fr - fr_max)\n",
    "\t\t\t\tdfr_mean_com.append(fr - fr_mean)\n",
    "\t\t\t\tdft_max_com.append(ft - ft_max)\n",
    "\t\t\t\tdft_mean_com.append(ft - ft_mean)\n",
    "\t\t\t\n",
    "\t\t\t# dfr_max_cv.append(np.std(dfr_max_com)/np.mean(dfr_max_com))\n",
    "\t\t\t# dfr_mean_cv.append(np.std(dfr_mean_com)/np.mean(dfr_mean_com))\n",
    "\t\t\t# dft_max_cv.append(np.std(dft_max_com)/np.mean(dft_max_com))\n",
    "\t\t\t# dft_mean_cv.append(np.std(dft_mean_com)/np.mean(dft_mean_com))\n",
    "\n",
    "\t\t\tdfr_max_mean.append(np.mean(dfr_max_com))\n",
    "\t\t\tdfr_max_std.append(np.std(dfr_max_com))\n",
    "\t\t\tdfr_mean_mean.append(np.mean(dfr_mean_com))\n",
    "\t\t\tdfr_mean_std.append(np.std(dfr_mean_com))\n",
    "\t\t\tdft_max_mean.append(np.mean(dft_max_com))\n",
    "\t\t\tdft_max_std.append(np.std(dft_max_com))\n",
    "\t\t\tdft_mean_mean.append(np.mean(dft_mean_com))\n",
    "\t\t\tdft_mean_std.append(np.std(dft_mean_com))\n",
    "\n",
    "\t\t#print(len(dfr_max_cv), dfr_max_cv)\n",
    "\t\tdfr_max_mean, dfr_max_std, dfr_mean_mean, dfr_mean_std = np.mean(dfr_max_mean), np.mean(dfr_max_std), np.mean(dfr_mean_mean), np.mean(dfr_mean_std)\n",
    "\t\tdft_max_mean, dft_max_std, dft_mean_mean, dft_mean_std = np.mean(dft_max_mean), np.mean(dft_max_std), np.mean(dft_mean_mean), np.mean(dft_mean_std)\n",
    "\t\tprint(f\"& {k} & {dfr_max_mean*100:.2f}\\\\% & {dfr_max_std*100:.2f}\\\\% & {dfr_mean_mean*100:.2f}\\\\% & {dfr_mean_std*100:.2f}\\\\% & \"\n",
    "\t\t\tf\"{dft_max_mean:.2f} & {dft_max_std:.2f} & {dft_mean_mean:.2f} & {dft_mean_std:.2f} \\\\\\\\\"\n",
    "\t\t)\n",
    "\n",
    "def compare_sequence():\n",
    "\tfor dataset in datasets:\n",
    "\t\tfor _, model in enumerate(models[dataset]):\n",
    "\t\t\tsequence_effect(dataset, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST_AlexNet_9938\n",
      "& 2 & 0.12\\% & 0.01\\% & 0.32\\% & 0.01\\% & -1.21 & 0.45 & 6.74 & 0.45 \\\\\n",
      "& 3 & 0.33\\% & 0.04\\% & 0.65\\% & 0.04\\% & -3.96 & 0.97 & 8.38 & 0.97 \\\\\n",
      "& 4 & 0.67\\% & 0.09\\% & 1.07\\% & 0.09\\% & -6.18 & 1.58 & 8.62 & 1.58 \\\\\n",
      "& 5 & 1.15\\% & 0.20\\% & 1.60\\% & 0.20\\% & -7.81 & 2.29 & 8.38 & 2.29 \\\\\n",
      "Caltech256_DenseNet121_6838\n",
      "& 2 & 2.35\\% & 0.11\\% & 5.82\\% & 0.11\\% & 62.33 & 3.81 & 152.19 & 3.81 \\\\\n",
      "& 3 & 5.14\\% & 0.19\\% & 10.46\\% & 0.19\\% & 128.11 & 6.16 & 262.48 & 6.16 \\\\\n",
      "& 4 & 8.22\\% & 0.31\\% & 14.70\\% & 0.31\\% & 190.84 & 10.30 & 351.24 & 10.30 \\\\\n",
      "& 5 & 11.51\\% & 0.41\\% & 18.74\\% & 0.41\\% & 250.14 & 13.80 & 425.67 & 13.80 \\\\\n",
      "VOC_MSRN\n",
      "& 2 & 1.38\\% & 0.09\\% & 3.92\\% & 0.09\\% & 22.43 & 2.38 & 79.00 & 2.38 \\\\\n",
      "& 3 & 2.90\\% & 0.22\\% & 6.71\\% & 0.22\\% & 43.71 & 3.30 & 124.20 & 3.30 \\\\\n",
      "& 4 & 4.54\\% & 0.35\\% & 9.07\\% & 0.35\\% & 65.72 & 5.34 & 159.12 & 5.34 \\\\\n",
      "& 5 & 6.26\\% & 0.44\\% & 11.22\\% & 0.44\\% & 86.39 & 7.06 & 187.39 & 7.06 \\\\\n",
      "COCO_MLD\n",
      "& 2 & 2.30\\% & 0.10\\% & 10.86\\% & 0.10\\% & 795.57 & 31.81 & 3937.00 & 31.81 \\\\\n",
      "& 3 & 4.26\\% & 0.19\\% & 17.39\\% & 0.19\\% & 1442.18 & 61.85 & 6228.27 & 61.85 \\\\\n",
      "& 4 & 6.06\\% & 0.25\\% & 21.99\\% & 0.25\\% & 2009.39 & 80.45 & 7792.22 & 80.45 \\\\\n",
      "& 5 & 7.91\\% & 0.32\\% & 25.54\\% & 0.32\\% & 2575.48 & 98.05 & 8959.91 & 98.05 \\\\\n"
     ]
    }
   ],
   "source": [
    "compare_sequence()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
